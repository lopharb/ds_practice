{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so here's a few quick ideas for a validation schema:\n",
    "\n",
    "- data shouldn't be shuffled before training, cause it's essential to have the time series values in consecutive order\n",
    "- currently I came up with three ideas for a schema:\n",
    "    1. `1,2train+3valid` -> `1,2,3train+4valid` -> `1,2,3,4train+5valid` etc.\n",
    "\n",
    "        **Advatages**:\n",
    "        - the train set grows, probably helping to test model's robustness\n",
    "        - we always validate on different parts of the training set\n",
    "\n",
    "        **Disadvantages**:\n",
    "        - computationally heavy. at some point our train will contain almost the entire dataset\n",
    "    2. `1,2train+3valid` -> `2,3train+4valid` -> `3,4train+5valid`\n",
    "\n",
    "        **Advantages**:\n",
    "        - fixed train size, no computational power issues\n",
    "        - we can somewhat efficiently use our dataset since we use each fold several times during different trainig sessions\n",
    "        \n",
    "        **Disadvantages**:\n",
    "        - the fact that different sets overlap might be a problem (shouldn't be, but who knows)\n",
    "    3.  `1,2train+3valid` -> `4,5train+6valid` -> `7,8train+9valid`\n",
    "\n",
    "        **Advantages**:\n",
    "        - the easiest one to implement, goes through each fold once only\n",
    "        - it's guaranteed that there's no overlapping or data leaks\n",
    "        \n",
    "        **Disadvantages**:\n",
    "        - data hugry in some sense, each fold is used only ones and each trainig session takes $f_{train} + 1$ folds, where $f_{train}$ is the amount of folds for the trainig set. this might be a problem assuming we have only 33 folds at maximum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model ideas:\n",
    "\n",
    "- **decision tree-based algorithms (boosting, random forest)**:\n",
    "\n",
    "    seems to be a good choice for the task since we have a lot of categorical features and the target is a discrete variable (which is typical for decision tree regression). at the same time, trees can be overfit easily, which can cause a huge loss in robustness and very inaccurate predictions on unseen data. ensembles will help to resolve this, but the problem of overfitting won't be gone completely. also, decision trees don't work well once something completely unseen shows up in input data, which might be a problem during future usage\n",
    "- **auto-regressive models**:\n",
    "\n",
    "    a time-series specific solution, that's supposed to do a good job at predicting future sales based on historical data. the main problems are the following: \n",
    "        1. I don't have any experience working with them (but we'll still try I guess)\n",
    "        2. the data is still quite noisy, so using AR models will require some additional preprocessing \n",
    "- **RNNs**:\n",
    "\n",
    "    one of the hardest models to implement, but at the same time a really powerfull (in theory) solution, that by definition fits the task idea quite well. RNNs can be really good when it comes to analyzing consecitive data (like text processing or time series) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "useful additional features:\n",
    "\n",
    "- day of the week\n",
    "- month\n",
    "- year\n",
    "- lagged values (look them up in `EDA`)\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "the point is to load the data in a format that's actually going to be fed to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import catboost as cb\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/processed_files/processed_data.csv')\n",
    "data['date'] = pd.to_datetime(data['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO should be moved to a dedicated file once i get everything working\n",
    "\n",
    "class FoldLoader:\n",
    "    \"\"\"\n",
    "    Provides tools for loading time series data, processing it and dividing into folds.\n",
    "    Is iterable\n",
    "\n",
    "    Example:\n",
    "\n",
    "    >>> loader = FoldLoader(your_data, 3, folding_mode='over')\n",
    "    >>> for train, val in loader:\n",
    "    >>>     # whatever we wanna do with the folds\n",
    "\n",
    "    This creates a FoldLoader with overlap folding mode.\n",
    "    After that, you can iterate through it using a for loop, where on each iteration\n",
    "    you recieve training and validation sets insize a 2-element tuple\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data: pd.DataFrame,  n_train_folds: int, n_valid_folds: int = 1, folding_mode: str = 'sequence') -> None:\n",
    "        \"\"\"\n",
    "        Constructs a FoldLoader object, sets its internal properties \n",
    "        (data source, training and validation sets size, folding mode)\n",
    "\n",
    "        Keyword arguments:\n",
    "\n",
    "        data -- a pandas dataframe containing the training data\n",
    "\n",
    "        target_col -- the name of a column in `data` contains the target values\n",
    "\n",
    "        n_train_folds -- the amount of months used to train the model.\n",
    "        must be less or equal to the amount of months in `data` minus n_valid_folds. \n",
    "        if `folding_mode` is 'stack', only affects the train size on the first iteration\n",
    "\n",
    "        n_valid_folds -- the amount of months used to validate the model.\n",
    "        must be less or equal to the amount of months in `data` minus n_train_folds\n",
    "        Default: 1\n",
    "\n",
    "        folding_mode -- one of \"sequence\", \"overlap\", \"stack\"\n",
    "        a string denoting the data splitting mode:\n",
    "            - `sequence` for `1,2train+3valid` -> `4,5train+6valid` -> `7,8train+9valid`\n",
    "            - `overlap` for `1,2train+3valid` -> `2,3train+4valid` -> `3,4train+5valid`\n",
    "            - `stack` for `1,2train+3valid` -> `1,2,3train+4valid` -> `1,2,3,4train+5valid`\n",
    "        Default: `sequence`\n",
    "        \"\"\"\n",
    "        self.min_fold = data['date_block_num'].unique().min()\n",
    "        self.max_fold = data['date_block_num'].unique().max()\n",
    "        self.current_fold = self.min_fold\n",
    "        self.train_size = n_train_folds\n",
    "        self.val_size = n_valid_folds\n",
    "        self.mode = folding_mode\n",
    "        self.len = 0\n",
    "        if self.mode.startswith('seq'):\n",
    "            self.len = (self.max_fold-self.min_fold +\n",
    "                        1)//(self.train_size+self.val_size)\n",
    "        elif self.mode.startswith('over'):\n",
    "            self.len = self.max_fold - self.min_fold - self.train_size - self.val_size + 2\n",
    "        elif self.mode.startswith('stack'):\n",
    "            self.len = (self.max_fold-self.min_fold +1) - self.val_size - (self.train_size-1)\n",
    "\n",
    "        if (self.max_fold - self.min_fold + 1) < self.train_size + self.val_size:\n",
    "            raise ValueError(\n",
    "                f'too many folds in train and valid for the given data')\n",
    "        tmp = pd.DataFrame()\n",
    "        tmp['income'] = data['item_price'] * data['item_cnt_day']\n",
    "        self.data = data[['date_block_num', 'shop_id',\n",
    "                          'item_id', 'item_cnt_day']].join(tmp, how='inner')\n",
    "        self.data = self.data.groupby(\n",
    "            ['date_block_num', 'shop_id', 'item_id'], as_index=False).sum()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.len\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess(data: pd.DataFrame, cat_features) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Preprocesses the input data. this includes the following:\n",
    "            - target encoding columns specified in `cat_features`\n",
    "            - forming additional features based on EDA results\n",
    "\n",
    "        Keyword arguments:\n",
    "\n",
    "        data -- data to be processed\n",
    "\n",
    "        cat_features -- list of column names present in `self.data` that will be\n",
    "        target encoded\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        pandas.DataFrame -- a new dataframe with the processed data \n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _get_item_internal(self, start_idx) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        iterates through the dataset to form the training and validation sets\n",
    "        for current iteration\n",
    "\n",
    "        Keyword arguments:\n",
    "\n",
    "        start_idx -- index of the fold (month) to start from\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        tuple(train, val) -- training and vaidation sets in form of a pandas DataFrame\n",
    "        \"\"\"\n",
    "        train = pd.DataFrame(columns=self.data.columns)\n",
    "        val = pd.DataFrame(columns=self.data.columns)\n",
    "\n",
    "        for idx in range(start_idx, start_idx + self.train_size):\n",
    "            train = pd.concat(\n",
    "                [train, self.data[self.data['date_block_num'] == idx]])\n",
    "        start_idx += self.train_size\n",
    "        for idx in range(start_idx, start_idx + self.val_size):\n",
    "            val = pd.concat(\n",
    "                [val, self.data[self.data['date_block_num'] == idx]])\n",
    "        return (train, val)\n",
    "\n",
    "    def __getitem__(self, idx) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        calls `_get_item_internal` to get training and validation sets.\n",
    "        adjusts internal counters corresponding to the selected folding mode.\n",
    "        Raises IndexError once the iteration is over\n",
    "\n",
    "        Keyword arguments:\n",
    "\n",
    "        idx -- not used in there since the data has to be consecutive.\n",
    "        however, it's mandatory to let __getitem__ take an index as input, \n",
    "        so there it is\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        tuple(train, val) -- training and vaidation sets in form of a pandas DataFrame\n",
    "        \"\"\"\n",
    "        if (self.current_fold+self.train_size+self.val_size - 1) > self.max_fold:\n",
    "            raise IndexError\n",
    "        start_idx = self.current_fold\n",
    "        if self.mode.startswith('seq'):\n",
    "            result = self._get_item_internal(start_idx)\n",
    "            self.current_fold += self.train_size+self.val_size\n",
    "            return result\n",
    "        elif self.mode.startswith('over'):\n",
    "            result = self._get_item_internal(start_idx)\n",
    "            self.current_fold += 1\n",
    "            return result\n",
    "        elif self.mode.startswith('stack'):\n",
    "            result = self._get_item_internal(start_idx)\n",
    "            self.train_size += 1\n",
    "            return result\n",
    "\n",
    "    def reset_folds(self) -> None:\n",
    "        \"\"\"\n",
    "        sets the current fold counter to point to the first fold \n",
    "        of the dataset. this effectively means that the iteration will be started over\n",
    "        \"\"\"\n",
    "        self.current_fold = self.min_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = FoldLoader(data, 3, folding_mode='seq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_block_num', 'shop_id', 'item_id', 'item_cnt_day', 'income'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = ['date_block_num', 'shop_id',\n",
    "               'item_id', 'income']\n",
    "target = 'item_cnt_day'\n",
    "cat_cols = ['date_block_num', 'shop_id', 'item_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_history = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost\n",
    "\n",
    "trying CatBoost with no additional parameters, we can then see the scores, compare to other models and decide wich one to use in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc49f5629a2499bb752ebd5fefaddd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: [ 1 out of  8]\tR2-score: [0.593]\tRMSE: [1.884]\n",
      "fold: [ 2 out of  8]\tR2-score: [0.782]\tRMSE: [1.776]\n",
      "fold: [ 3 out of  8]\tR2-score: [0.824]\tRMSE: [2.008]\n",
      "fold: [ 4 out of  8]\tR2-score: [0.823]\tRMSE: [1.610]\n",
      "fold: [ 5 out of  8]\tR2-score: [0.730]\tRMSE: [2.022]\n",
      "fold: [ 6 out of  8]\tR2-score: [0.836]\tRMSE: [1.916]\n",
      "fold: [ 7 out of  8]\tR2-score: [0.598]\tRMSE: [2.367]\n",
      "fold: [ 8 out of  8]\tR2-score: [0.626]\tRMSE: [1.990]\n"
     ]
    }
   ],
   "source": [
    "template = 'fold: [{:2} out of {:2}]\\tR2-score: [{:3.3f}]\\tRMSE: [{:3.3f}]'\n",
    "index = 1\n",
    "history = {'loss': [], 'score': []}\n",
    "loader.reset_folds()\n",
    "for train, val in tqdm(loader):\n",
    "    # fetch data\n",
    "    train_data = cb.Pool(train[in_features], train[target], cat_features=cat_cols)\n",
    "    val_data = cb.Pool(val[in_features], val[target])\n",
    "    # reset the model\n",
    "    model = cb.CatBoostRegressor(cat_features=cat_cols, thread_count=8)\n",
    "    model.fit(train_data, verbose=False)\n",
    "\n",
    "    # validate\n",
    "    preds = model.predict(val[in_features])\n",
    "    rmse = (np.sqrt(mean_squared_error(val[target], preds)))\n",
    "    r2 = r2_score(val[target], preds)\n",
    "    history['score'].append(r2)\n",
    "    history['loss'].append(rmse)\n",
    "    print(template.format(index, len(loader), r2, rmse))\n",
    "    index += 1\n",
    "global_history['catboost'] = history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest\n",
    "\n",
    "this one requires manually encoding some features, since it can't process categorical features out-of-the-box. again, planning to see the scores I get and compare to others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN\n",
    "\n",
    "requires encoding cat. features too."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
